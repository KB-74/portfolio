{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from tensorflow.keras import backend as K\n",
    "import model as yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = './yolo.h5'\n",
    "ANCHOR_PATH = './yolo_anchors.txt'\n",
    "CLASS_PATH = './coco_classes.txt'\n",
    "INPUT_VIDEO = 'undistorted_cameradata/camera_3.mp4'\n",
    "OUTPUT_PATH = 'object_detection_test_4.avi'\n",
    "VIDEO_OUTPUT = {\n",
    "    'width': 640,\n",
    "    'height': 480\n",
    "}\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    config = tf.ConfigProto(intra_op_parallelism_threads=4,\n",
    "                            inter_op_parallelism_threads=4, allow_soft_placement=True, \\\n",
    "                            device_count={'CPU': 1, 'GPU': 1})\n",
    "    sess = tf.Session(config=config)\n",
    "    K.set_session(sess)\n",
    "\n",
    "sess = K.get_session()\n",
    "yolo_model = models.load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "input_image_shape = K.placeholder(shape=(2,))\n",
    "\n",
    "\n",
    "def _get_anchors(path=ANCHOR_PATH):\n",
    "    anchors_path = os.path.expanduser(path)\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def _get_class(path=CLASS_PATH):\n",
    "    classes_path = os.path.expanduser(path)\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "\n",
    "class_names = _get_class()\n",
    "anchors = _get_anchors()\n",
    "\n",
    "\n",
    "def generate():\n",
    "    boxes, scores, classes = yolo.yolo_eval(yolo_model.output, anchors, len(class_names), input_image_shape)\n",
    "\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "boxes, scores, classes = generate()\n",
    "\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w / iw, h / ih)\n",
    "    nw = int(iw * scale)\n",
    "    nh = int(ih * scale)\n",
    "\n",
    "    image = image.resize((nw, nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128, 128, 128))\n",
    "    new_image.paste(image, ((w - nw) // 2, (h - nh) // 2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def detect_image(image):\n",
    "    new_image_size = (image.width - (image.width % 32), image.height - (image.height % 32))\n",
    "    boxed_image = letterbox_image(image, new_image_size)\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "    print('start running in session')\n",
    "\n",
    "    out_boxes, out_scores, out_classes = sess.run(\n",
    "        [boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            yolo_model.input: image_data,\n",
    "            input_image_shape: [image.size[1], image.size[0]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "\n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                              size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    hsv_tuples = [(x / len(class_names), 1., 1.)\n",
    "                  for x in range(len(class_names))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + i, top + i, right - i, bottom - i],\n",
    "                outline=colors[c])\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "            fill=colors[c])\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
    "# cap.set(1, 3120)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (VIDEO_OUTPUT['width'], VIDEO_OUTPUT['height']))\n",
    "\n",
    "counter = 0\n",
    "while True:\n",
    "\n",
    "    # read the frames\n",
    "    hasNext, frame = cap.read()\n",
    "\n",
    "    # end the loop of no frame is left to process\n",
    "    if not counter < 10:\n",
    "        break\n",
    "\n",
    "    if not hasNext:\n",
    "        break\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (VIDEO_OUTPUT['width'], VIDEO_OUTPUT['height']))\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = detect_image(frame)\n",
    "\n",
    "    out.write(np.array(frame))\n",
    "    counter = counter + 1\n",
    "    print('count {}'.format(counter))\n",
    "\n",
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
